- [课程链接](https://designgurus.org/path-player?courseid=grokking-the-system-design-interview)
-
- ## System Design Guide
  collapsed:: true
	- ### System Design Interviews: A step by step guide
	  collapsed:: true
		- **Step 1: Requirements clarifications**
			- It is always a good idea to ask questions about the exact scope of the problem we are trying to solve. Candidates who spend enough time to define the end goals of the system always have a better chance to be successful in the interview.
		- **Step 2: Back-of-the-envelope estimation**
			- It is always a good idea to estimate the scale of the system we’re going to design. This will also help later when we focus on scaling, partitioning, load balancing, and caching.
			- scale, storage, network bandwidth
		- **Step 3: System interface definition**
			- Define what APIs are expected from the system. This will establish the exact contract expected from the system and ensure if we haven’t gotten any requirements wrong.
		- **Step 4: Defining data model**
			- Defining the data model in the early part of the interview will clarify how data will flow between different system components.
			- Later, it will guide for data partitioning and management.
				- storage, transportation, encryption
		- **Step 5: High-level design**
			- Draw a block diagram with **5-6 boxes** representing the core components of our system. We should identify enough components that are needed to solve the actual problem from end to end.
		- **Step 6: Detailed design**
			- Dig deeper into two or three major components; the interviewer’s feedback should always guide us to what parts of the system need further discussion.
			- We should present different approaches, their pros and cons, and explain why we will prefer one approach over the other.
				- Remember, there is no single answer; the only important thing is to consider tradeoffs between different options while keeping system constraints in mind.
		- **Step 7: Identifying and resolving bottlenecks**
			- Try to discuss as many bottlenecks as possible and different approaches to mitigate them.
				- single point of failure
				- replicas of the data
				- enough copies of different services
				- monitoring the performance, get alerts whenever critical components fail or their performance degrades
		- Preparation and being organized during the interview are the keys to success in system design interviews.
	- ### Designing a URL Shortening service like TinyURL
	  collapsed:: true
		- **1. Why do we need URL shortening?**
		- **2. Requirements and Goals of the System**
			- You should always clarify requirements at the beginning of the interview. Be sure to ask questions to find the exact scope of the system that the interviewer has in mind.
			- Functional Requirements, Non-Functional Requirements, Extended Requirements
		- **3. Capacity Estimation and Constraints**
			- **Traffic estimates**, **Storage estimates**, **Bandwidth estimates**, **Memory estimates**
			- **High-level estimates** (Summary)
		- **4. System APIs**
			- Once we've finalized the requirements, it's always a good idea to define the system APIs. This should explicitly state what is expected from the system.
			- **How do we detect and prevent abuse?**
		- **5. Database Design**
			- Defining the DB schema in the early stages of the interview would help to understand the data flow among various components and later would guide towards data partitioning.
			- **Database Schema**
			- **What kind of database should we use?**
				- [SQL vs. NoSQL](https://designgurus.org/path-player?courseid=grokking-the-system-design-interview&unit=grokking-the-system-design-interview_1627054379423_8Unit)
		- **6. Basic System Design and Algorithm**
			- Hash or **Key Generation Service (KGS)**
		- **7. Data Partitioning and Replication**
			- **Range Based Partitioning** or **Hash-Based Partitioning**
				- [Consistent Hashing](https://designgurus.org/path-player?courseid=grokking-the-system-design-interview&unit=grokking-the-system-design-interview_1627054411532_11Unit)
		- **8. Cache**
			- **cache memory**, **cache eviction policy **
		- **9. Load Balancer (LB)**
		- **10. Purging or DB cleanup**
		- **11. Telemetry**
		- **12. Security and Permissions**
			- permission level (public/private)
- ## System Design Problems
	- ### Designing Pastebin
	  collapsed:: true
		- We can assume a 5:1 ratio between the read and write.
		- Users can upload maximum 10MB of data; commonly Pastebin like services are used to share source code, configs, or logs. Such texts are not huge, so let’s assume that each paste on average contains 10KB.
		- To keep some margin, we will assume a 70% capacity model (meaning we don’t want to use more than 70% of our total storage capacity at any point),
		- Following the 80-20 rule, meaning 20% of hot pastes generate 80% of traffic, we would like to cache these 20% pastes.
		- ‘ContentKey’ is a reference to an external object storing the contents of the paste
		- Since we are generating a random key, there is a possibility that the newly generated key could match an existing one. In that case, we should regenerate a new key and try again. We should keep retrying until we don’t see failure due to the duplicate key.
	- ### Designing Instagram
	  collapsed:: true
		- High Availability
		- The acceptable latency of the system is 200ms for News Feed generation.
		- We may need to use SQL database, but relational databases come with their challenges, especially when we need to scale them.
		- In data stores, deletes don’t get applied instantly; data is retained for certain days (to support undeleting) before getting removed from the system permanently.
		- We can split reads and writes into separate services. We will have dedicated servers for reads and different servers for writes to ensure that uploads don’t hog the system.
		- Losing files is not an option for our service. Therefore, we will store multiple copies of each file so that if one storage server dies, we can retrieve the photo from the other copy present on a different storage server.
		- KGS single point of failure: A workaround for that could be to define two such databases, one generating even-numbered IDs and the other odd-numbered. (load balancer)
		- **Pre-generating the News Feed:** We can have dedicated servers that are continuously generating users’ News Feeds and storing them in a ‘UserNewsFeed’ table. So whenever any user needs the latest photos for their News-Feed, we will simply query this table and return the results to the user.
			- **Pull or Push?**
				- **Hybrid:** We can adopt a hybrid approach. We can move all the users who have a high number of followers to a pull-based model and only push data to those who have a few hundred (or thousand) follows. Another approach could be that the server pushes updates to all the users not more than a certain frequency and letting users with a lot of followers/updates to pull data regularly.
	- ### Designing Dropbox
	  collapsed:: true
		- **Availability:** The motto of cloud storage services is to have data availability anywhere, anytime. Users can access their files/photos from any device whenever and wherever they like.
		- **Reliability and Durability:** Another benefit of cloud storage is that it offers 100% reliability and durability of data. Cloud storage ensures that users will never lose their data by keeping multiple copies of the data stored on different geographically located servers.
		- **Requirements**, **Some Design Considerations**
			- We should expect huge read and write volumes. Read to write ratio is expected to be nearly the same.
			- Keeping a local copy of the metadata (file name, size, etc.) with the client can save us a lot of round trips to the server.
			- For small changes, clients can intelligently upload the diffs instead of the whole chunk.
		- **High Level Design**
			- ![](https://lwfiles.mycourse.app/systemdesign-public/a754f17f56ef778b4bfb9fc9dc44b1cc.png)
		- **Component Design**
			- ![](https://lwfiles.mycourse.app/systemdesign-public/be5db77680fed602be8334e2ab24f9a6.png)
			- **Client**
				- The Client Application monitors the workspace folder on the user’s machine and syncs all files/folders in it with the remote Cloud Storage.
				- **How do we handle file transfer efficiently?**
					- Chunk: divide each file into fixed sizes of 4MB chunks.
				- **Should we keep a copy of metadata with Clients?**
					- YES. Keeping a local copy of metadata not only enables us to do offline updates but also saves a lot of round trips to update remote metadata.
				- **How can clients efficiently listen to changes happening with other clients?**
					- periodically check
					- HTTP long polling
				- **divide our client into four parts**
					- **Internal Metadata Database**
					- **Chunker**
					- **Watcher**
					- **Indexer** (events handler)
			- **Metadata Database**
				- The Metadata Database is responsible for maintaining the versioning and metadata information about files/chunks, users, and workspaces.
				- SQL or NoSQL?
					- a consistent view
					- ACID!
			- **Synchronization Service**
				- The Synchronization Service is the component that processes file updates made by a client and applies these changes to other subscribed clients.
				- The Synchronization Service is the most important part of the system architecture due to its critical role in managing the metadata and synchronizing users’ files.
				- The Synchronization Service should be designed to transmit less data between clients and the Cloud Storage to achieve a better response time.
					- just transmit the difference between two versions of a file
					- dividing our files into 4MB chunks
					- calculate a hash (e.g., SHA-256) to see whether to update the local copy of a chunk or not
				- The messaging middleware should provide scalable message queuing and change notifications to support a high number of clients using pull or push strategies.
			- **Message Queuing Service**
				- An important part of our architecture is a messaging middleware that should be able to handle a substantial number of requests. A scalable Message Queuing Service that supports asynchronous message-based communication between clients and the Synchronization Service best fits the requirements of our application.
				- ![](https://lwfiles.mycourse.app/systemdesign-public/5f5dd592905d3126b83b8a05d57fc9ae.png)
			- **Cloud/Block Storage**
				- Cloud/Block Storage stores chunks of files uploaded by the users.
		- **File Processing Workflow**
			- The sequence below shows the interaction between the components of the application in a scenario when Client A updates a file that is shared with Client B and C, so they should receive the update too. If the other clients are not online at the time of the update, the Message Queuing Service keeps the update notifications in separate response queues for them until they come online later.
			- **Procedure**
				- Client A uploads chunks to cloud storage.
				- Client A updates metadata and commits changes.
				- Client A gets confirmation and notifications are sent to Clients B and C about the changes.
				- Client B and C receive metadata changes and download updated chunks.
		- **Data Deduplication**
			- For each new incoming chunk, we can calculate a hash of it and compare that hash with all the hashes of the existing chunks to see if we already have the same chunk present in our storage.
			- **Post-process deduplication**
			- **In-line deduplication**
		- **Metadata Partitioning**
			- To scale out metadata DB, we need to partition it so that it can store information about millions of users and billions of files/chunks.
		-
	- ### Designing Facebook Messenger
		- Messenger’s high availability is desirable; we can tolerate lower availability in the interest of consistency.
		- **Messages Handling**
			- **How would we efficiently send/receive messages?**
				- **Push model:** Users can keep a connection open with the server and can depend upon the server to notify them whenever there are new messages.
			- **How can the server keep track of all the opened connections to efficiently redirect messages to the users?**
				- The server can maintain a hash table, where “key” would be the UserID and “value” would be the connection object. So whenever the server receives a message for a user, it looks up that user in the hash table to find the connection object and sends the message on the open request.
			- **What will happen when the server receives a message for a user who has gone offline?**
				- If the receiver has disconnected, the server can notify the sender about the delivery failure. However, if it is a temporary disconnect, e.g., the receiver’s long-poll request just timed out, then we should expect a reconnect from the user. In that case, we can ask the sender to retry sending the message. This retry could be embedded in the client’s logic so that users don’t have to retype the message. The server can also store the message for a while and retry sending it once the receiver reconnects.
			- **How many chat servers do we need?**
				- Let’s plan for 500 million connections at any time. Assuming **a modern server can handle 50K concurrent connections** at any time, we would need 10K such servers.
			-
			-
- ## Glossary of System Design Basics
	- ### System Design Basics
	  collapsed:: true
		- Whenever we are designing a large system, we need to consider a few things:
			- What are the different architectural pieces that can be used?
			- How do these pieces work with each other?
			- How can we best utilize these pieces: what are the right tradeoffs?
		- Investing in scaling before it is needed is generally not a smart business proposition
	- ### SQL vs. NoSQL
	  collapsed:: true
		- Relational databases are structured and have predefined schemas like phone books that store phone numbers and addresses.
		- Non-relational databases are unstructured, distributed, and have a dynamic schema like file folders that hold everything from a person’s address and phone number to their Facebook ‘likes’ and online shopping preferences.
		- **SQL**
			- Relational databases store data in rows and columns. Each row contains all the information about one entity and each column contains all the separate data points.
			- Some of the most popular relational databases are MySQL, Oracle, MS SQL Server, SQLite, Postgres, and MariaDB.
		- **NoSQL**
			- **Key-Value Stores**: Redis, Voldemort, and Dynamo
			- **Document Databases**: CouchDB and MongoDB
			- **Wide-Column Databases**
				- In columnar databases we have column families, which are containers for rows.
				- Unlike relational databases, we don’t need to know all the columns up front and each row doesn’t have to have the same number of columns.
				- Columnar databases are best suited for analyzing large datasets - big names include Cassandra and HBase.
			- **Graph Databases**
				- Data is saved in graph structures with nodes (entities), properties (information about the entities), and lines (connections between the entities).
				- Examples of graph database include Neo4J and InfiniteGraph.
		- **High level differences between SQL and NoSQL**
			- **Storage**
			- **Schema**
			- **Querying**
			- **Scalability**
				- In most common situations, SQL databases are vertically scalable, NoSQL databases are horizontally scalable.
			- **Reliability or ACID Compliancy (Atomicity, Consistency, Isolation, Durability)**
				- The vast majority of relational databases are ACID compliant.
				- Most of the NoSQL solutions sacrifice ACID compliance for performance and scalability.
		- **Which one to use?**
			- When it comes to database technology, there’s no one-size-fits-all solution.
			- Many businesses rely on both relational and non-relational databases for different needs
			- **Reasons to use SQL database**
				- We need to ensure ACID compliance.
				- Your data is structured and unchanging.
			- **Reasons to use NoSQL database**
				- Storing large volumes of data that often have little to no structure.
				- Making the most of cloud computing and storage.
				- Rapid development.
	- ### Consistent Hashing
	  collapsed:: true
		- David Karger et al. first introduced Consistent Hashing in their [1997 paper](https://dl.acm.org/doi/10.1145/258533.258660) and suggested its use in distributed caching.
		- The act of distributing data across a set of nodes is called data partitioning.
			- How do we know on which node a particular piece of data will be stored?
			- When we add or remove nodes, how do we know what data will be moved from existing nodes to the new nodes? Additionally, how can we minimize data movement when nodes join or leave?
		- Consistent Hashing maps data to physical nodes and ensures that **only a small set of keys move when servers are added or removed.**
		- Vnodes are **randomly distributed** across the cluster and are generally **non-contiguous** so that no two neighboring Vnodes are assigned to the same physical node or rack.
		- **Dynamo** and **Cassandra** use Consistent Hashing to distribute their data across nodes.
	- **Long-Polling vs WebSockets vs Server-Sent Events**
	  collapsed:: true
		- **HTTP Long-Polling**
			- With Long-Polling, the client requests information from the server exactly as in normal polling, but with the expectation that the server may not respond immediately. That’s why this technique is sometimes referred to as a “Hanging GET”.
		- **WebSockets**
			- WebSocket provides [Full duplex](https://en.wikipedia.org/wiki/Duplex_(telecommunications)#Full_duplex) communication channels over a single TCP connection.
		- **Server-Sent Events (SSEs)**
			- Under SSEs the client establishes a persistent and long-term connection with the server. The server uses this connection to send data to a client. If the client wants to send data to the server, it would require the use of another technology/protocol to do so.
-