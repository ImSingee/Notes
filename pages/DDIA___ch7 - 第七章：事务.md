alias:: DDIA/ch7

- [link](https://github.com/Vonng/ddia/blob/master/ch7.md)
-
- 在数据系统的残酷现实中，很多事情都可能出错：
	- 数据库软件、硬件可能在任意时刻发生故障（包括写操作进行到一半时）。
	- 应用程序可能在任意时刻崩溃（包括一系列操作的中间）。
	- 网络中断可能会意外切断数据库与应用的连接，或数据库之间的连接。
	- 多个客户端可能会同时写入数据库，覆盖彼此的更改。
	- 客户端可能读取到无意义的数据，因为数据只更新了一部分。
	- 客户端之间的竞争条件可能导致令人惊讶的错误。
- **事务（transaction）** 一直是简化这些问题的首选机制。事务是应用程序将多个读写操作组合成一个逻辑单元的一种方式。从概念上讲，事务中的所有读写操作被视作单个操作来执行：整个事务要么成功 **提交**（commit），要么失败 **中止**（abort）或 **回滚**（rollback）。如果失败，应用程序可以安全地重试。
- 事务不是天然存在的；它们是为了 **简化应用编程模型** 而创建的。通过使用事务，应用程序可以自由地忽略某些潜在的错误情况和并发问题，因为数据库会替应用处理好这些。（我们称之为 **安全保证**，即 safety guarantees）。
- **并不是所有的应用都需要事务**，有时候弱化事务保证、或完全放弃事务也是有好处的（例如，为了获得更高性能或更高可用性）。一些安全属性也可以在没有事务的情况下实现。
-
## 事务的棘手概念
	- 现今，几乎所有的关系型数据库和一些非关系数据库都支持 **事务**
	- 2000 年以后，非关系（NoSQL）数据库开始普及。它们的目标是在关系数据库的现状基础上，通过提供新的数据模型选择并默认包含复制（第五章）和分区（第六章）来进一步提升。事务是这次运动的主要牺牲品：这些新一代数据库中的许多数据库完全放弃了事务，或者重新定义了这个词，描述比以前所理解的更弱得多的一套保证
	- 随着这种新型分布式数据库的*炒作*，人们普遍认为*事务是可伸缩性的对立面*
		- 当然，这是错误的
	- ### ACID的含义
		- ACID 代表 **原子性（Atomicity）**，**一致性（Consistency）**，**隔离性（Isolation）** 和 **持久性（Durability）**
			- 它由 Theo Härder 和 Andreas Reuter 于 1983 年提出，旨在为数据库中的容错机制建立*精确的术语*
			- 但实际上，不同数据库的 ACID 实现并不相同 —— 高层次上的想法很美好，但魔鬼隐藏在细节里
		- 不符合 ACID 标准的系统有时被称为 BASE，它代表 **基本可用性（Basically Available）**，**软状态（Soft State）** 和 **最终一致性（Eventual consistency）**
			- 这比 ACID 的定义更加模糊，似乎 BASE 的唯一合理的定义是 “不是 ACID”，即它几乎可以代表任何你想要的东西
		- #### A 原子性
			- 一般来说，原子是指不能分解成小部分的东西
				- 这个词在计算机的不同领域中意味着相似但又微妙不同的东西
					- 例如，在多线程编程中，如果一个线程执行一个原子操作，这意味着另一个线程无法看到该操作的一半结果。
					- 系统只能处于操作之前或操作之后的状态，而不是介于两者之间的状态
			- 相比之下，ACID 的原子性并 **不** 是关于 **并发（concurrent）** 的。它并不是在描述如果几个进程试图同时访问相同的数据会发生什么情况
				- 这是隔离性
			- ACID 原子性的定义特征是：**能够在错误时中止事务，丢弃该事务进行的所有写入变更的能力。** 或许 **可中止性（abortability）** 是更好的术语
		- #### C 一致性
			- 一致性这个词被赋予太多含义：
				- 副本一致性、异步复制系统中的最终一致性问题
				- 一致性哈希是某些系统用于重新分区的一种分区方法。
				- CAP 定理中，一致性一词用于表示线性一致性
				- 在 ACID 的上下文中，**一致性** 是指数据库在应用程序的特定概念中处于 “良好状态”。
			- ACID 一致性的概念是，**对数据的一组特定约束必须始终成立**，即 **不变式（invariants）**
				- 例如，会计，借贷必相等
			- 但是，一致性的这种概念取决于应用程序对不变式的理解
				- 应用程序负责正确定义它的事务，并保持一致性
				- 这并不是数据库可以保证的事情：如果你写入违反不变式的脏数据，数据库也无法阻止你
				- 一些特定类型的不变式可以由数据库检查，例如外键约束或唯一约束，但是一般来说，是应用程序来定义什么样的数据是有效的，什么样是无效的—— 数据库只管存储
			- 原子性、隔离性和持久性是数据库的属性，而一致性（在 ACID 意义上）是应用程序的属性。应用可能依赖数据库的原子性和隔离性来实现一致性，但这并不仅取决于数据库。因此，字母 C 不属于 ACID
				- 乔・海勒斯坦（Joe Hellerstein）指出，在 Härder 与 Reuter 的论文中，“ACID 中的 C” 是被 “扔进去凑缩写单词的”，而且那时候大家都不怎么在乎一致性
		- #### I 隔离性
			- 大多数数据库都会同时被多个客户端访问。如果它们各自读写数据库的不同部分，这是没有问题的，但是如果它们访问相同的数据库记录，则可能会遇到 **并发** 问题（**竞争条件**，即 race conditions）。
			- ACID 意义上的隔离性意味着，**同时执行的事务是相互隔离的**：它们不能相互冒犯
				- 传统的数据库教科书将隔离性形式化为 **可串行化（Serializability）**
				- 这意味着每个事务可以假装它是唯一在整个数据库上运行的事务。数据库确保当多个事务被提交时，结果与它们串行运行（一个接一个）是一样的，尽管实际上它们*可能*是并发运行的
			- **而实践中很少会使用可串行的隔离，因为它有性能损失**
		- #### D 持久性
			- 数据库系统的目的是，提供一个安全的地方存储数据，而不用担心丢失。**持久性** 是一个承诺，即**一旦事务成功完成**，即使发生硬件故障或数据库崩溃，写入的任何数据也不会丢失。
				- 在单节点数据库中，持久性通常意味着数据已被写入非易失性存储设备，如硬盘或 SSD。它通常还包括预写日志或类似的文件
				- 在带复制的数据库中，持久性可能意味着数据已成功复制到一些节点。
				- 为了提供持久性保证，数据库必须等到这些写入或复制完成后，才能报告事务成功提交。
			- **完美的持久性是不存在的** ：如果所有硬盘和所有备份同时被销毁，那显然没有任何数据库能救得了你。
				- 如果所有硬盘和所有备份同时被销毁，那显然没有任何数据库能救得了你
	- ### 单对象和多对象操作
		- 在 ACID 中，原子性和隔离性描述了客户端在同一事务中执行多次写入时，数据库应该做的事情；这些定义假设你想同时修改多个对象（行，文档，记录）。通常需要 **多对象事务（multi-object transaction）** 来保持多块数据同步
		- 多对象事务需要某种方式来确定哪些读写操作属于同一个事务。在关系型数据库中，通常基于客户端与数据库服务器的 TCP 连接：在任何特定连接上，`BEGIN TRANSACTION` 和 `COMMIT` 语句之间的所有内容，被认为是同一事务的一部分
		- #### 单对象写入
			- 锁：对单节点上的单个对象（例如键值对）上提供原子性和隔离性。原子性可以通过使用日志来实现崩溃恢复、使用每个对象上的锁来实现隔离
			- 原子操作：CAS
			- 这些单对象操作很有用，因为它们可以防止在多个客户端尝试同时写入同一个对象时丢失更新，**但它们不是通常意义上的事务**
				- AS 以及其他单一对象操作被称为 “轻量级事务”，甚至出于营销目的被称为 “ACID”
				- 但是这个术语是误导性的。事务通常被理解为，**将多个对象上的多个操作合并为一个执行单元的机制**。
		- #### 多对象事务的需求
			- **许多分布式数据存储已经放弃了多对象事务，因为多对象事务很难跨分区实现，而且在需要高可用性或高性能的情况下，它们可能会碍事**
			- **没有原子性，错误处理就要复杂得多，缺乏隔离性，就会导致并发问题**
		- #### 处理错误和中止
			- 事务的一个关键特性是，如果发生错误，它可以中止并安全地重试
			- ACID 数据库基于这样的哲学：如果数据库有违反其原子性，隔离性或持久性的危险，则宁愿完全放弃事务，而不是留下半成品
				- 然而并不是所有的系统都遵循这个哲学。特别是具有无主复制的数据存储，主要是在 “尽力而为” 的基础上进行工作。可以概括为 “数据库将做尽可能多的事，运行遇到错误时，它不会撤消它已经完成的事情” —— 所以，**从错误中恢复是应用程序的责任**。
			- 错误发生不可避免，但许多软件开发人员倾向于只考虑乐观情况，而不是错误处理的复杂性
				- 重申：**中止的重点就是允许安全的重试**
				- 然而，重试可能导致问题
					- 如果事务实际上成功了，但是在服务器试图向客户端确认提交成功时网络发生故障，那么重试事务会导致事务被执行两次
						- 解决：额外的应用级去重机制
					- 如果错误是由于负载过大造成的，则重试事务将使问题变得更糟
						- 解决：限制重试次数、使用指数退避算法、单独处理与过载相关的错误
					- 仅在临时性错误（例如，由于死锁，异常情况，临时性网络中断和故障切换）后才值得重试。在发生永久性错误（例如，违反约束）之后重试是毫无意义的
					- 如果事务在数据库之外也有副作用，即使事务被中止，也可能发生这些副作用。例如，如果你正在发送电子邮件，那你肯定不希望每次重试事务时都重新发送电子邮件。如果你想确保几个不同的系统一起提交或放弃，**两阶段提交（2PC, two-phase commit）** 可以提供帮助
					- 如果客户端进程在重试中失效，任何试图写入数据库的数据都将丢失
## 弱隔离级别
	- 如果两个事务不触及相同的数据，它们可以安全地 **并行（parallel）** 运行，因为两者都不依赖于另一个。当一个事务读取由另一个事务同时修改的数据时，或者当两个事务试图同时修改相同的数据时，并发问题（竞争条件）才会出现。
	- 数据库一直试图通过提供 **事务隔离（transaction isolation）** 来隐藏应用程序开发者的并发问题。从理论上讲，隔离可以通过假装没有并发发生，让你的生活更加轻松：**可串行的（serializable）** 隔离等级意味着数据库保证事务的效果如同串行运行（即一次一个，没有任何并发）。
	- 实际上不幸的是：隔离并没有那么简单。**可串行的隔离** 会有性能损失，许多数据库不愿意支付这个代价
	- ### 读已提交
		- 最基本的事务隔离级别是 **读已提交（Read Committed）**
			- 从数据库读时，只能看到已提交的数据（没有 **脏读**，即 dirty reads）。
			- 写入数据库时，只会覆盖已提交的数据（没有 **脏写**，即 dirty writes）。
		- #### 没有脏读
			- 设想一个事务已经将一些数据写入数据库，但事务还没有提交或中止。另一个事务可以看到未提交的数据吗？如果是的话，那就叫做 **脏读（dirty reads）**
			- 在 **读已提交** 隔离级别运行的事务必须防止脏读。这意味着事务的任何写入操作只有在该事务提交时才能被其他人看到（然后所有的写入操作都会立即变得可见）
			- 为什么要没有脏读？
				- 如果事务需要更新多个对象，脏读取意味着另一个事务可能会只看到一部分更新
					- 例如，电子邮件场景，可能先看到计数器而看不到邮件
				- 果事务中止，则所有写入操作都需要回滚
					- 如果数据库允许脏读，那就意味着一个事务可能会看到稍后需要回滚的数据，即从未实际提交给数据库的数据。想想后果就让人头大
		- #### 没有脏写
			- 如果两个事务同时尝试更新数据库中的相同对象，会发生什么情况？我们不知道写入的顺序是怎样的，但是**我们通常认为后面的写入会覆盖前面的写入**。
			- 但是，如果先前的写入是尚未提交事务的一部分，又会发生什么情况，后面的写入会覆盖一个尚未提交的值？这被称作 **脏写（dirty write）**。
			- 在 **读已提交** 的隔离级别上运行的事务必须防止脏写，通常是延迟第二次写入，直到第一次写入事务提交或中止为止。
			- 为什么要防止脏写？
				- 如果事务更新多个对象，脏写会导致不好的结果
					- 例如，关联计数器，可能造成关联约束被破坏
				- 但是，读已提交并不能防止同一个计数器两次增加时的竞争状态
		- #### 实现读已提交
			- **读已提交** 是一个非常流行的隔离级别
			- **防止脏写**：数据库通过使用 **行锁（row-level lock）** 来防止脏写：当事务想要修改特定对象（行或文档）时，它必须首先获得该对象的锁。然后必须持有该锁直到事务被提交或中止。一次只有一个事务可持有任何给定对象的锁；**如果另一个事务要写入同一个对象，则必须等到第一个事务提交或中止后，才能获取该锁并继续**。这种锁定是读已提交模式（或更强的隔离级别）的数据库自动完成的。
			- **防止脏读**：可以选锁方案，但是性能差
				- 大多数数据库：对于写入的每个对象，数据库都会记住旧的已提交值，和由当前持有写入锁的事务设置的新值。当事务正在进行时，任何其他读取对象的事务都会拿到旧值。 只有当新值提交后，事务才会切换到读取新值
	- ### 快照隔离和可重复读
		- **不可重复读（nonrepeatable read）** 或 **读取偏差（read skew）**：事务中读取同一值两次，在两次之间已提交的事务变更可以看到，会产生不一致的困惑
		- 解决方案：**快照隔离（snapshot isolation）**
			- 每个事务都从数据库的 **一致快照（consistent snapshot）** 中读取 —— 也就是说，事务可以看到事务开始时在数据库中提交的所有数据。即使这些数据随后被另一个事务更改，每个事务也只能看到该特定时间点的旧数据。
			- 快照隔离对长时间运行的只读查询（如备份和分析）非常有用。如果查询的数据在查询执行的同时发生变化，则很难理解查询的含义。当一个事务可以看到数据库在某个特定时间点冻结时的一致快照，理解起来就很容易了。
		- #### 实现快照隔离
			- 与读取提交的隔离类似，快照隔离的实现通常使用写锁来防止脏写
			- 为了实现快照隔离，数据库必须可能保留一个对象的几个不同的提交版本，因为各种正在进行的事务可能需要看到数据库在不同的时间点的状态。因为它同时维护着单个对象的多个版本，所以这种技术被称为 **多版本并发控制（MVCC, multi-version concurrency control）**。
			- 如果一个数据库只需要提供 **读已提交** 的隔离级别，而不提供 **快照隔离**，那么保留一个对象的两个版本就足够了：已提交的版本和被覆盖但尚未提交的版本。不过支持快照隔离的存储引擎通常也使用 MVCC 来实现 **读已提交** 隔离级别。一种典型的方法是 **读已提交** 为每个查询使用单独的快照，而 **快照隔离** 对整个事务使用相同的快照。
		- #### 观察一致性快照的可见性规则
			- 如果以下两个条件都成立，则可见一个对象：
				- 读事务开始时，创建该对象的事务已经提交。
				- 对象未被标记为删除，或如果被标记为删除，请求删除的事务在读事务开始时尚未提交。
		- #### 索引和快照隔离
			- 索引如何在多版本数据库中工作？一种选择是使索引简单地指向对象的所有版本，并且需要索引查询来过滤掉当前事务不可见的任何对象版本。当垃圾收集删除任何事务不再可见的旧对象版本时，相应的索引条目也可以被删除。
			- 在实践中，许多实现细节决定了多版本并发控制的性能。例如，如果同一对象的不同版本可以放入同一个页面中，PostgreSQL 的优化可以避免更新索引
			- 使用仅追加的 B 树，每个写入事务（或一批事务）都会创建一棵新的 B 树，当创建时，从该特定树根生长的树就是数据库的一个一致性快照。没必要根据事务 ID 过滤掉对象，因为后续写入不能修改现有的 B 树；它们只能创建新的树根。但这种方法也需要一个负责压缩和垃圾收集的后台进程。
		- #### 可重复读与命名混淆
			- 快照隔离是一个有用的隔离级别，特别对于只读事务而言。但是，许多数据库实现了它，却用不同的名字来称呼
				- 在 Oracle 中称为 **可串行化（Serializable）** 的，在 PostgreSQL 和 MySQL 中称为 **可重复读（repeatable read）**
			- 这种命名混淆的原因是 SQL 标准没有 **快照隔离** 的概念
	- ### 防止丢失更新
		- **读已提交** 和 **快照隔离** 级别，主要保证了 **只读事务在并发写入时** 可以看到什么。却忽略了两个事务并发写入的问题
		- 并发的写入事务之间还有其他几种有趣的冲突。其中最著名的是 **丢失更新（lost update）** 问题
			- 读取 - 修改 - 写入
			- 中间有其他人改了，会让其丢失
		- #### 原子写
			- 原子更新操作
			- 原子操作通常通过在读取对象时，获取其上的排它锁来实现。以便更新完成之前没有其他事务可以读取它。这种技术有时被称为 **游标稳定性（cursor stability）**；另一个选择是简单地强制所有的原子操作在单一线程上执行
			- **ORM 框架很容易意外地执行不安全的读取 - 修改 - 写入序列，而不是使用数据库提供的原子操作**
		- #### 显式锁定
			- 某些情况下，一个原子操作可能是不够的（关联的情形）
			- `SELECT FOR UPDATE`
				- 让应用程序显式地锁定将要更新的对象。然后应用程序可以执行读取 - 修改 - 写入序列，如果任何其他事务尝试同时读取同一个对象，则强制等待，直到第一个 **读取 - 修改 - 写入序列** 完成
		- #### 自动检测丢失的更新
			- 原子操作和锁是通过强制 **读取 - 修改 - 写入序列** 按顺序发生，来防止丢失更新的方法。另一种方法是允许它们并行执行，如果事务管理器检测到丢失更新，则中止事务并强制它们重试其 **读取 - 修改 - 写入序列**
			- 种方法的一个优点是，数据库可以结合快照隔离高效地执行此检查
				- PostgreSQL 的可重复读，Oracle 的可串行化和 SQL Server 的快照隔离级别，都会自动检测到丢失更新，并中止惹麻烦的事务
				- 但是，MySQL/InnoDB 的可重复读并不会检测 **丢失更新**
					- 一些人认为，数据库必须能防止丢失更新才称得上是提供了 **快照隔离**，所以在这个定义下，MySQL 下不提供快照隔离
			- 丢失更新检测是一个很好的功能，因为它不需要应用代码使用任何特殊的数据库功能，你可能会忘记使用锁或原子操作，从而引入错误；但丢失更新的检测是自动发生的，因此不太容易出错。
		- #### 比较并设置（CAS）
			- ```sql
			  UPDATE wiki_pages SET content = '新内容'
			    WHERE id = 1234 AND content = '旧内容';
			  ```
			- 如果内容已经更改并且不再与 “旧内容” 相匹配，则此更新将不起作用，因此你需要检查更新是否生效，必要时重试。但是，如果数据库允许 `WHERE` 子句从旧快照中读取，则此语句可能无法防止丢失更新，因为即使发生了另一个并发写入，`WHERE` 条件也可能为真。在依赖数据库的 CAS 操作前要检查其是否安全。
		- #### 冲突解决和复制
			- 在复制数据库中，**由于在多个节点上存在数据副本，并且在不同节点上的数据可能被并发地修改，因此需要采取一些额外的步骤来防止丢失更新**
			- 最后写入胜利（LWW）的冲突解决方法很容易丢失更新；不幸的是，LWW 是许多复制数据库中的默认方案
	- ### 写入偏差与幻读
		- **写入偏差**
			- 因为这两个事务正在更新两个不同的对象，但是有冲突
			- 可以将写入偏差视为丢失更新问题的一般化
		- **如果无法使用可串行化的隔离级别，则此情况下的次优选项可能是显式锁定事务所依赖的行**
		- #### 写入偏差的更多例子
			- 写入偏差乍看像是一个深奥的问题，但一旦意识到这一点，很容易会注意到它可能发生在更多场景下
			- 会议室预订系统
				- 预定范围重叠
			- 多人游戏
				- 将两个不同的棋子移动到棋盘上的相同位置
			- 抢注用户名
			- 防止双重开支
		- #### 导致写入偏差的幻读
			- 这种效应：一个事务中的写入改变另一个事务的搜索查询的结果，被称为 **幻读**
			- 快照隔离避免了只读查询中幻读，但是在像我们讨论的例子那样的读写事务中，幻读会导致特别棘手的写入偏差情况
		- #### 物化冲突
			- **物化冲突（materializing conflicts）**：将幻读变为数据库中一组具体行上的锁冲突
				- 在会议室预订的场景中，可以想象创建一个关于时间槽和房间的表。此表中的每一行对应于特定时间段（例如 15 分钟）的特定房间。可以提前插入房间和时间的所有可能组合行
				- 现在，要创建预订的事务可以锁定（`SELECT FOR UPDATE`）表中与所需房间和时间段对应的行。在获得锁定之后，它可以检查重叠的预订并像以前一样插入新的预订。请注意，这个表并不是用来存储预订相关的信息 —— 它完全就是一组锁，用于防止同时修改同一房间和时间范围内的预订。
			- 不幸的是，弄清楚如何物化冲突可能很难，也很容易出错，并且让并发控制机制泄漏到应用数据模型是很丑陋的做法。出于这些原因，如果没有其他办法可以实现，物化冲突应被视为最后的手段。在大多数情况下。**可串行化（Serializable）** 的隔离级别是更可取的。
## 可串行化
	- **可串行化（Serializability）** 隔离通常被认为是最强的隔离级别。它保证即使事务可以并行执行，最终的结果也是一样的，就好像它们没有任何并发性，连续挨个执行一样。因此数据库保证，如果事务在单独运行时正常运行，则它们在并发运行时继续保持正确 —— 换句话说，数据库可以防止 **所有** 可能的竞争条件。
	- ### 真的串行执行
		- 避免并发问题的最简单方法就是完全不要并发：在单个线程上按顺序一次只执行一个事务。这样做就完全绕开了检测 / 防止事务间冲突的问题，由此产生的隔离，正是可串行化的定义。
		- 可行性：OLTP 事务通常很短，而且只进行少量的读写操作
		- 具有单线程串行事务处理的系统不允许交互式的多语句事务。取而代之，应用程序必须提前将整个事务代码作为存储过程提交给数据库
		- **实现要求**
			- 每个事务都必须小而快
			- 活跃数据集必须放入内存
			- 写入吞吐量必须低到能在单个 CPU 核上处理
				- 分区：事务需要能划分至单个分区，且不需要跨分区协调
					- 跨分区事务是可能的，但是它们能被使用的程度有很大的限制
	- ### 两阶段锁定
		- *几十年来唯一可行的选择*
		- **两阶段锁定（2PL，two-phase locking）**
			- 请注意，虽然两阶段锁定（2PL）听起来非常类似于两阶段提交（2PC），但它们是完全不同的东西
		- 锁通常用于防止脏写；两阶段锁定类似，但是锁的要求更强得多。只要没有写入，就允许多个事务同时读取同一个对象。但对象只要有写入（修改或删除），就需要 **独占访问（exclusive access）** 权限
			- 如果事务 A 读取了一个对象，并且事务 B 想要写入该对象，那么 B 必须等到 A 提交或中止才能继续（这确保 B 不能在 A 底下意外地改变对象）。
			- 如果事务 A 写入了一个对象，并且事务 B 想要读取该对象，则 B 必须等到 A 提交或中止才能继续
			- > 似乎就是 Rust 的读写引用规则？
		- #### 实现两阶段锁
			- PL 用于 MySQL（InnoDB）和 SQL Server 中的可串行化隔离级别，以及 DB2 中的可重复读隔离级别
			- 读与写的阻塞是通过为数据库中每个对象添加锁来实现的。锁可以处于 **共享模式（shared mode）** 或 **独占模式（exclusive mode）**
				- 若事务要读取对象，则须先以共享模式获取锁。允许多个事务同时持有共享锁。但如果另一个事务已经在对象上持有排它锁，则这些事务必须等待
				- 若事务要写入一个对象，它必须首先以独占模式获取该锁。没有其他事务可以同时持有锁（无论是共享模式还是独占模式），所以如果对象上存在任何锁，该事务必须等待
				- **如果事务先读取再写入对象，则它可能会将其共享锁升级为独占锁。升级锁的工作与直接获得独占锁相同**
				- 事务获得锁之后，必须继续持有锁直到事务结束（提交或中止）
					- “两阶段” 这个名字的来源：**第一阶段（当事务正在执行时）获取锁，第二阶段（在事务结束时）释放所有的锁**
			- 由于使用了这么多的锁，因此很可能会发生：事务 A 等待事务 B 释放它的锁，反之亦然。这种情况叫做 **死锁（Deadlock）**。数据库会自动检测事务之间的死锁，并中止其中一个，以便另一个继续执行。被中止的事务需要由应用程序重试。
		- #### 两阶段锁定的性能
			- 两阶段锁定下的事务吞吐量与查询响应时间要比弱隔离级别下要差得多
			- 原因一：锁开销
			- 原因二：不确定的等待时间
				- 传统的关系数据库不限制事务的持续时间，因为它们是为等待人类输入的交互式应用而设计的
				- 当一个事务需要等待另一个事务时，等待的时长并没有限制
			- 原因三：更容易死锁，重试导致开销
				- 基于锁实现的读已提交隔离级别可能发生死锁，但在基于 2PL 实现的可串行化隔离级别中，它们会出现的频繁的多（取决于事务的访问模式）。这可能是一个额外的性能问题：当事务由于死锁而被中止并被重试时，它需要从头重做它的工作。如果死锁很频繁，这可能意味着巨大的浪费。
		- #### 谓词锁
			- **幻读（phantoms）**：一个事务改变另一个事务的搜索查询的结果
				- 具有可串行化隔离级别的数据库必须防止 **幻读**
			- 幻读引入的问题在于不应该读到不该读到的数据
				- **谓词锁（predicate lock）**
					- 它类似于前面描述的共享 / 排它锁，但不属于特定的对象（例如，表中的一行），它**属于所有符合某些搜索条件的对象**
				- 如果事务 A 想要读取匹配某些条件的对象，它必须获取查询条件上的 **共享谓词锁（shared-mode predicate lock）**。如果另一个事务 B 持有任何满足这一查询条件对象的排它锁，那么 A 必须等到 B 释放它的锁之后才允许进行查询。
				- 如果事务 A 想要插入，更新或删除任何对象，则必须首先检查旧值或新值是否与任何现有的谓词锁匹配。如果事务 B 持有匹配的谓词锁，那么 A 必须等到 B 已经提交或中止后才能继续。
			- 关键思想：谓词锁甚至适用于数据库中尚不存在，但将来可能会添加的对象（幻象）
			- **如果两阶段锁定包含谓词锁，则数据库将阻止所有形式的写入偏差和其他竞争条件，因此其隔离实现了可串行化。**
		- #### 索引范围锁
			- 谓词锁性能不佳：**如果活跃事务持有很多锁，检查匹配的锁会非常耗时**
			- 大多数使用 2PL 的数据库实际上实现了索引范围锁（index-range locking，也称为 **next-key locking**），这是一个简化的近似版谓词锁
			- 思路：通过使谓词匹配到一个更大的集合来简化谓词锁
				- 索引范围锁并不像谓词锁那样精确（它们可能会锁定更大范围的对象，而不是维持可串行化所必需的范围），但是由于它们的开销较低，所以是一个很好的折衷
				- 如果没有可以挂载范围锁的索引，数据库可以退化到使用整个表上的共享锁
	- ### 可串行化快照隔离
		- **可串行化快照隔离（SSI, serializable snapshot isolation）** 的算法是非常有前途的。它提供了完整的可串行化隔离级别，但与快照隔离相比只有很小的性能损失
		- #### 悲观与乐观的并发控制
			- 两阶段锁是一种所谓的 **悲观并发控制机制（pessimistic）** ：它是基于这样的原则：如果有事情可能出错（如另一个事务所持有的锁所表示的），最好等到情况安全后再做任何事情。这就像互斥，用于保护多线程编程中的数据结构
			- **串行化快照隔离** 是一种 **乐观（optimistic）** 的并发控制技术。在这种情况下，乐观意味着，如果存在潜在的危险也不阻止事务，而是继续执行事务，希望一切都会好起来。当一个事务想要提交时，数据库检查是否有什么不好的事情发生（即隔离是否被违反）；如果是的话，事务将被中止，并且必须重试
		- #### 基于过时前提的决策
			- 数据库如何知道查询结果是否可能已经改变？有两种情况需要考虑：
				- 检测对旧 MVCC 对象版本的读取（读之前存在未提交的写入）
				- 检测影响先前读取的写入（读之后发生写入）
				-
## 本章小结
-
-